[model]
; The train files for the 
train_file = data/es_en/es_en.slam.20171218.train
dev_file = data/es_en/es_en.slam.20171218.dev
dev_key = data/es_en/es_en.slam.20171218.dev.key
test_file = data/es_en/es_en.slam.20171218.test
test_key = data/es_en/es_en.slam.20171218.test.key
output_predictions = result/es_en.pred

[options]
# In our final experiments we make use of the dev data; use_dev = True
use_dev = True
; The number of the iterations logistic regression algorithm executes
nepochs = 10
# Sigma is the L2 prior variance, regularizing the baseline model. Smaller sigma means more regularization.
sigma = 30.0
; Larger means larger step size.
learning_rate = 0.40

[context_features]
; This uses the previous and the current token as a sparse feature in the model
use_prev_current_token = True
use_current_next_token = True
use_prev_current_metaphone = True
use_current_next_metaphone = True
use_prev_current_pos = True
use_current_next_pos = True
use_first_token = True